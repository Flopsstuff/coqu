## Context

API использует `console.log` в паре мест без структуры. Нет способа отследить что происходит на сервере: авторизации, CRUD-операции, клонирование, ошибки. Администратору нужен обзор активности и инструмент диагностики прямо в интерфейсе.

Текущий стек: Express + Prisma, React SPA. Все маршруты в одном файле `api/src/index.ts`. Веб-приложение с роутингом через react-router.

## Goals / Non-Goals

**Goals:**
- Структурированное логирование с уровнями и категориями
- Запись в файлы с дневной ротацией через Pino
- REST API для чтения логов с фильтрацией
- Страница просмотра логов в UI

**Non-Goals:**
- Real-time стриминг логов (WebSocket) — можно добавить позже
- Полнотекстовый поиск по логам
- Экспорт логов
- Логирование HTTP-запросов целиком (request/response body)

## Decisions

### 1. Pino + pino-roll для записи

**Выбор:** Pino с transport `pino-roll` в worker thread.

**Альтернативы:**
- Winston — медленнее, тяжелее, но более гибкий. Избыточен для наших нужд.
- Своё на `fs` — ноль зависимостей, но нужно самому писать буферизацию, ротацию, обработку ошибок FS.

**Обоснование:** Pino — самый быстрый Node.js логгер, pino-roll даёт ротацию из коробки, transport работает в отдельном worker thread и не блокирует event loop.

### 2. Формат и структура файлов

**Формат:** NDJSON (одна JSON-строка на запись). Pino пишет именно так.

**Структура директории:**
```
{LOG_DIR}/
  app.2026-02-21.log
  app.2026-02-20.log
  ...
```

`LOG_DIR` настраивается через env `LOG_DIR`, по умолчанию `./logs`.

**Ротация:** Ежедневно по дате. Удаление файлов старше N дней (настраиваемо через `LOG_RETENTION_DAYS`, по умолчанию 30).

### 3. Структура лог-записи

```json
{
  "level": 30,
  "time": 1708531200000,
  "msg": "Project cloned successfully",
  "category": "git",
  "projectId": "abc-123",
  "userId": "user-456"
}
```

Pino использует числовые уровни: 10=trace, 20=debug, 30=info, 40=warn, 50=error, 60=fatal.

Наши категории: `auth`, `projects`, `agents`, `git`, `system`.

### 4. Модуль логгера

Создаём `api/src/logger.ts` — единственная точка входа для логирования:

```typescript
import { logger } from "./logger";
logger.info({ category: "git", projectId: id }, "Clone started");
```

Также экспортируем child-логгер с предустановленной категорией:

```typescript
const gitLog = logger.child({ category: "git" });
gitLog.info({ projectId: id }, "Clone started");
```

### 5. Чтение логов через API

**Эндпоинт:** `GET /api/logs`

**Подход:** Читаем нужные файлы по дате, парсим NDJSON построчно, фильтруем, возвращаем с пагинацией.

**Параметры:** `date` (YYYY-MM-DD), `level` (info/warn/error), `category`, `limit`, `offset`.

По умолчанию: сегодняшняя дата, все уровни, limit=100.

**Порядок:** Новые записи первыми (reversed). Читаем файл с конца.

### 6. Очистка старых логов

При старте сервера и раз в сутки (setInterval) запускается cleanup: удаляет файлы старше `LOG_RETENTION_DAYS`.

## Risks / Trade-offs

**[Большие файлы при высокой нагрузке]** → На нашем масштабе (self-hosted, один пользователь) нереалистично. Если станет проблемой — добавить ротацию по размеру.

**[Чтение больших файлов блокирует event loop]** → Используем stream-based чтение (readline). Limit по умолчанию 100 записей.

**[Потеря логов при крэше]** → Pino worker thread буферизирует. Минимальный риск, приемлемо для нашего use case.

**[Нет поиска по тексту]** → Non-goal. Фильтрации по level/category/date достаточно для начала.
